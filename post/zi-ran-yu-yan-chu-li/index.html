
<!DOCTYPE html>
<html>
  <head>
    
<meta charset="utf-8" >

<title>自然语言处理 | 书生海海</title>
<meta name="description" content="温故而知新">

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://aprilspring.github.io/favicon.ico?v=1667029754307">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://aprilspring.github.io/styles/main.css">


  
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css" />
  

  


<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>



  </head>
  <body>
    <div id="app" class="main">
      <div class="site-header-container">
  <div class="site-header">
    <div class="left">
      <a href="https://aprilspring.github.io">
        <img class="avatar" src="https://aprilspring.github.io/images/avatar.png?v=1667029754307" alt="" width="32px" height="32px">
      </a>
      <a href="https://aprilspring.github.io">
        <h1 class="site-title">书生海海</h1>
      </a>
    </div>
    <div class="right">
      <transition name="fade">
        <i class="icon" :class="{ 'icon-close-outline': menuVisible, 'icon-menu-outline': !menuVisible }" @click="menuVisible = !menuVisible"></i>
      </transition>
    </div>
  </div>
</div>

<transition name="fade">
  <div class="menu-container" style="display: none;" v-show="menuVisible">
    <div class="menu-list">
      
        
          <a href="/" class="menu purple-link">
            首页
          </a>
        
      
        
          <a href="/archives" class="menu purple-link">
            归档
          </a>
        
      
        
          <a href="/tags" class="menu purple-link">
            标签
          </a>
        
      
        
          <a href="/post/about" class="menu purple-link">
            关于
          </a>
        
      
    </div>
  </div>
</transition>


      <div class="content-container">
        <div class="post-detail">
          
          <h2 class="post-title">自然语言处理</h2>
          <div class="post-info post-detail-info">
            <span><i class="icon-calendar-outline"></i> 2018-07-12</span>
            
              <span>
                <i class="icon-pricetags-outline"></i>
                
                  <a href="https://aprilspring.github.io/tag/UGg7JjI7b/">
                    NLP
                    
                  </a>
                
              </span>
            
          </div>
          <div class="post-content" v-pre>
            <p>根据这一阵子对文本分析的研究，做了一些整理，可供参考。<br>
有不对之处，恳请大家指正。</p>
<h2 id="预料库">预料库</h2>
<blockquote>
<p>1）直接下载现成的语料库<br>
2）爬虫方法获取语料库<br>
3）当前分析的所有文本形成语料库</p>
</blockquote>
<h2 id="文本预处理">文本预处理</h2>
<blockquote>
<p>主要包括：<br>
1）文本删除（文本去重复、机械压缩去词、短句删除、去除无效标签等）<br>
2）编码转换<br>
3）拼写检查（针对英文）<br>
4）大小写统一（针对英文）<br>
5）分词<br>
6）去停用词（网上提供1208个停用词：https://pan.baidu.com/s/1gfMXMl9）</p>
</blockquote>
<!--more-->
<h2 id="分词方法">分词方法</h2>
<blockquote>
<p>主要包括：<br>
<strong>1）jieba分词</strong><br>
2）哈工大ltp、中科院ICTLAS、东北大学NIU parser<br>
3）nltk分词</p>
</blockquote>
<pre><code class="language-python"># jieba分词示例
import jieba
word = '我是一个小学生，新来的呢'
word_cut = []
word_cut.append(' '.join(jieba.cut_for_search(word)))

#output
['我 是 一个 小学 学生 小学生 ， 新来 的 呢']
</code></pre>
<h2 id="文本向量化">文本向量化</h2>
<p>在分词和预处理之后，需要对文本进行向量化。</p>
<p><strong>one-hot词向量：</strong></p>
<blockquote>
<p>1）词袋向量化：每个单词是否出现，0/1值</p>
</blockquote>
<pre><code>from sklearn.feature_extraction.text import CountVectorizer 
</code></pre>
<blockquote>
<p>2）词频向量化：计算每个单词在总体中出现的频率，[0,1]值</p>
</blockquote>
<pre><code># TfidfVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

# or

# TfidfModel
from gensim.models import TfidfModel

# or

# HashingVectorizer
from sklearn.feature_extraction.text import HashingVectorizer
</code></pre>
<p><strong>分布式词向量：</strong></p>
<blockquote>
<p>word2vec</p>
</blockquote>
<pre><code>from gensim.models import Word2Vec
</code></pre>
<h2 id="文本分析的应用">文本分析的应用</h2>
<h3 id="1-情感分析">1. 情感分析</h3>
<p><strong>情感分析词库：</strong></p>
<blockquote>
<p>1）WordNet和SentiWordNet<br>
2）知网整理的HowNet词典、台湾大学发布的NTUSD中文词典以及大连理工大学的中文情感词汇本体。</p>
</blockquote>
<p><strong>中文情感分析：</strong></p>
<blockquote>
<p>可以自定义正、负情感的预料库，替换安装路径下的文件：./snownlp/sentiment/pos.txt和neg.txt</p>
</blockquote>
<pre><code># pip install snownlp
# 返回积极情绪的概率
from snownlp import SnowNLP

def chinese_emotion(string):
    obj = SnowNLP(string)
    s = obj.sentences
    if len(s) &gt; 1:
        ss = ''
        for i in s:
            ss += str(i)
    else:
        ss = str(s)
    freq = SnowNLP(ss).sentiments
    return string, freq
</code></pre>
<p><strong>英文情感分析：</strong></p>
<pre><code># pip install textblob
# python -m textblob.download_corpora # 返回积极情绪概率polarity和主管情绪概率subjectivity

from textblob import TextBlob

def english_emotion(string):
    obj = TextBlob(string)
    freq = obj.sentiment.polarity
    return string, freq
</code></pre>
<h3 id="2-敏感词检测">2. 敏感词检测</h3>
<blockquote>
<p>1）基于内容相似性、固定信息过滤等方法（DFA方法）<br>
2）朴素贝叶斯等有监督模型</p>
</blockquote>
<pre><code># DFA
# 需要调用：https://github.com/ericzh/smallgfw/smallgfw.py
gfw.check(row)
gfw.set([&quot;sexy&quot;,&quot;girl&quot;,&quot;love&quot;,&quot;shit&quot;]) #设置敏感词库
gfw.replace(&quot;Shit!,Cherry is a sexy girl. She loves python.&quot;,&quot;*&quot;) #替换敏感词
gfw.check(&quot;Shit!,Cherry is a sexy girl. She loves python.&quot;) #检测敏感词的出现位置
</code></pre>
<h3 id="3-主题模型挖掘">3. 主题模型挖掘</h3>
<p><strong>LDA 主题模型算法：</strong></p>
<blockquote>
<p>建立主题分析模型，识别输入文本的主题（自定义主题个数）</p>
</blockquote>
<pre><code>from gensim import corpora, models
models.LdaModel()
# or
import lda
</code></pre>
<p><strong>pLDA模型：</strong></p>
<blockquote>
<p>从全部文章的所有词语中找出N个作为主题，再计算出每篇文章属于这N个主题的权重</p>
</blockquote>
<p><strong>LSI模型：</strong></p>
<blockquote>
<p>通过奇异值分解的方法计算出文本中各个主题的概率分布</p>
</blockquote>
<pre><code>import gensim
</code></pre>
<p><strong>关键词抽提：</strong></p>
<blockquote>
<p>1）基于TF-IDF算法</p>
</blockquote>
<pre><code>from jieba.analyse import extract_tags
</code></pre>
<blockquote>
<p>2）基于TextRank算法</p>
</blockquote>
<pre><code>from jieba.analyse import textrank
</code></pre>
<h3 id="4-基于上下文的文本分类">4. 基于上下文的文本分类</h3>
<p><strong>word2vec模型：</strong></p>
<blockquote>
<p>1）输入层：分词后的文本<br>
2）投影层：<br>
模型参数说明：https://blog.csdn.net/szlcw1/article/details/52751314<br>
输入文本多个词向量求平均：https://blog.csdn.net/liugallup/article/details/51164962<br>
3）输出层：分布式词向量、词语间相似性判断</p>
</blockquote>
<pre><code># word2vec模型构建
from jieba.analyse import textrank
sentences = word2vec.Text8Corpus(path + 'corpus_afterSeg.txt') #加载预料库
model = word2vec.Word2Vec(sentences, min_count=min_count, size=size, window=window, workers=workers)
model.save(path + 'corpus.model')
model.wv.save_word2vec_format(path + 'corpus.model.bin', binary = True)

# 模型预测
vec = model[word]
print(vec)
</code></pre>
<p><strong>Doc2Vec 模型：</strong></p>
<blockquote>
<p>输入为段落向量</p>
</blockquote>
<p><strong>FastText模型：</strong></p>
<blockquote>
<p>与word2vec类似，速度更快，目前仅支持Linux和Mac系统下操作<br>
fasttext格式：‘_ label _ _ X  Text blabla... ’<br>
遗留问题：为什么模型的precision一直等于recall ?</p>
</blockquote>
<pre><code>import fasttext
classifier = fasttext.supervised('fasttext_train.txt','fasttext.model',label_prefix='__label__',lr=0.05, dim=200, min_count=3,loss='softmax',encoding='utf-8')
# classifier = fasttext.load_model('fasttext.model.bin', label_prefix='__label__')
result = classifier.test(&quot;fasttext_test.txt&quot;)
print(result.precision) #0.765
print(result.recall)
print(result.nexamples)
</code></pre>
<h3 id="5-文本相似度计算">5. 文本相似度计算</h3>
<pre><code>from gensim import corpora, models, similarities
</code></pre>
<h3 id="6-搜索优化模型">6. 搜索优化模型</h3>
<blockquote>
<p>暂未了解。</p>
</blockquote>
<h3 id="鸣谢">鸣谢！</h3>
<p><em>fastText | 我爱自然语言处理 http://www.52nlp.cn/tag/fasttext</em><br>
<em>Facebook的NLP库的使用：利用FastText进行文本分类和词提示 | ATYUN http://www.atyun.com/3590.html</em><br>
<em>使用fasttext实现文本处理及文本预测 - CSDN博客 https://blog.csdn.net/meyh0x5vDTk48P2/article/details/79055553</em><br>
<em>GitHub - facebookresearch/fastText https://github.com/facebookresearch/fastText</em><br>
<em>win7 python3.6安装fasttext | 易学教程 https://www.e-learn.cn/content/python/632699</em><br>
<em>词语向量化-word2vec简介和使用 - CSDN博客 https://blog.csdn.net/xsdxs/article/details/72951545</em><br>
<em>gensim函数库的Word2Vec的参数说明 - CSDN博客 https://blog.csdn.net/szlcw1/article/details/52751314</em><br>
<em>词向量：对word2vec的理解 - CSDN博客 https://blog.csdn.net/sinat_33741547/article/details/78759289</em><br>
<em>情感分析资源 （转） - Charleston - 博客园 http://www.cnblogs.com/finesite/p/3381803.html</em><br>
<em>NLP之淘宝商品评论情感分析 https://zhuanlan.zhihu.com/p/29747435</em><br>
<em>Dataset | Yongfeng Zhang http://yongfeng.me/dataset/</em><br>
<em>GitHub - Codelegant92/SentimentAnalysis-chinese https://github.com/Codelegant92/SentimentAnalysis-chinese</em><br>
<em>GitHub - isnowfy/snownlp: Python library for processing Chinese text https://github.com/isnowfy/snownlp</em><br>
<em>GitHub - build2last/EC-Master: 电商爬虫与观点挖掘 https://github.com/build2last/EC-Master</em></p>

          </div>
        </div>

        
          <div class="next-post">
            <a class="purple-link" href="https://aprilspring.github.io/post/ji-qi-xue-xi-du-xu-yao-dong-sha/">
              <h3 class="post-title">
                下一篇：机器学习都需要懂啥？
              </h3>
            </a>
          </div>
          
      </div>

      
        
          <div id="gitalk-container"></div>
        

        
      

      <div class="site-footer">
  <div class="slogan">温故而知新</div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://aprilspring.github.io/atom.xml" target="_blank">RSS</a>
</div>


    </div>
    <script type="application/javascript">

hljs.initHighlightingOnLoad()

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>



  
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
    <script>

      var gitalk = new Gitalk({
        clientID: '337e2992c146020878cb',
        clientSecret: '883fa6db7cdfafda50356191ec9938e4d661aca1',
        repo: 'AprilSpring.github.io',
        owner: 'AprilSpring',
        admin: ['AprilSpring'],
        id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
        distractionFreeMode: false  // Facebook-like distraction free mode
      })

      gitalk.render('gitalk-container')

    </script>
  

  




  </body>
</html>
